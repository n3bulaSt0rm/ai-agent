import os
import base64
import json
import asyncio
import logging
import time

from datetime import datetime, time as datetime_time
from typing import Dict, Any, List, Optional, Tuple
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from email.utils import parsedate_to_datetime
from pathlib import Path

# Gmail API
from google.auth.transport.requests import Request
from google.oauth2.credentials import Credentials
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError


# Import Vietnamese Query Module
from backend.services.processing.rag.retrievers.qdrant_retriever import VietnameseQueryModule, create_query_module
from backend.services.processing.rag.embedders.text_embedder import VietnameseEmbeddingModule
from backend.core.config import settings
from backend.db.metadata import get_metadata_db

from backend.services.processing.rag.draft_monitor import EmailDraftMonitor

from backend.services.processing.rag.utils import (
    create_deepseek_client, DeepSeekAPIClient, 
    extract_image_attachments, extract_text_content
)

# Gemini Email Processor import  
from backend.services.processing.rag.extractors.gemini.gemini_email_processor import GeminiEmailProcessor

# Import background worker and API monitor
from backend.services.processing.rag.gmail_api_monitor import create_gmail_api_monitor
from backend.services.processing.rag.gmail_background_worker import GmailThreadWorker

# Configure logging
logger = logging.getLogger(__name__)



class GmailHandler:
    """
    Gmail handler that processes emails with multimodal content using Gemini
    """
    
    def __init__(self, token_path: str = None):
        """
        Initialize Gmail handler with Gemini always enabled.
        
        Args:
            token_path: Path to the token JSON file  
        """
        self.token_path = token_path or settings.GMAIL_TOKEN_PATH
        self.service = None
        self.user_id = 'me'
        
        try:
            self.gemini_processor = GeminiEmailProcessor()
            logger.info("Gemini email processor initialized for attachment processing")
        except Exception as e:
            logger.error(f"Gemini initialization failed: {e}")
            raise Exception(f"Required Gemini processor failed to initialize: {e}")
        
        self.deepseek_api_key = settings.DEEPSEEK_API_KEY
        self.deepseek_api_url = settings.DEEPSEEK_API_URL
        self.deepseek_model = settings.DEEPSEEK_MODEL
        
        self.deepseek_client = create_deepseek_client(
            deepseek_api_key=self.deepseek_api_key,
            deepseek_api_url=self.deepseek_api_url,
            deepseek_model=self.deepseek_model
        )
        
        self.query_module = None
        
        self.metadata_db = get_metadata_db()
        
        self.draft_monitor = None
        self.api_monitor = None
        
        self.background_worker = None
        
        if not self.deepseek_api_key:
            logger.warning("DEEPSEEK_API_KEY not set in settings")
    
    def _initialize_managers(self):
        """Initialize draft monitor and API monitor after authentication."""
        if not self.service:
            logger.error("Gmail service not authenticated, cannot initialize managers")
            return
        
        self.draft_monitor = EmailDraftMonitor(
            service=self.service,
            metadata_db=self.metadata_db,
            user_id=self.user_id
        )
        
        self.api_monitor = create_gmail_api_monitor(gmail_handler=self, poll_interval=settings.GMAIL_POLL_INTERVAL)
        
        logger.info("Draft monitor and Gmail API monitor initialized successfully")

    def _init_background_worker(self):
        """Initialize background worker (called separately after authentication)"""
        if not self.service:
            logger.error("Gmail service not authenticated, cannot initialize background worker")
            return False
        
        try:
            self.background_worker = GmailThreadWorker(
                gmail_service=self.service,
                user_id=self.user_id
            )
            self.background_worker.start()
            logger.info("Gmail background worker initialized and started")
            return True
        except Exception as e:
            logger.error(f"Failed to initialize background worker: {e}")
            return False

    def _init_query_module(self):
        """
        Initialize the Vietnamese Query Module if not already initialized
        """
        if self.query_module is not None:
            return
            
        try:
            # Try to get embedding module and memory manager from server modules
            memory_manager = None
            embedding_module = None
            try:
                # Import here to avoid circular imports
                from backend.services.processing.server import modules
                if hasattr(modules, 'cuda_memory_manager') and modules.cuda_memory_manager:
                    memory_manager = modules.cuda_memory_manager
                    logger.info("Using shared CUDA Memory Manager from server")
                if hasattr(modules, 'embedding_module') and modules.embedding_module:
                    embedding_module = modules.embedding_module
                    logger.info("Using shared Embedding Module from server")
            except (ImportError, AttributeError) as e:
                logger.warning(f"Could not import modules from server: {e}")
            
            # Create embedding module only if not available from server
            if not embedding_module:
                logger.info("Creating new VietnameseEmbeddingModule for Gmail handler")
                embedding_module = VietnameseEmbeddingModule(
                    qdrant_host=settings.QDRANT_HOST,
                    qdrant_port=settings.QDRANT_PORT,
                    collection_name=settings.QDRANT_COLLECTION_NAME,
                    dense_model_name=settings.DENSE_MODEL_NAME,
                    sparse_model_name=settings.SPARSE_MODEL_NAME,
                    reranker_model_name=settings.RERANKER_MODEL_NAME,
                    vector_size=settings.VECTOR_SIZE,
                    memory_manager=memory_manager 
                )
            
            self.query_module = create_query_module(
                embedding_module=embedding_module,
                deepseek_api_key=self.deepseek_api_key,
                memory_manager=memory_manager,  
                deepseek_model=self.deepseek_model,
                limit=5,
                candidates_limit=10,
                dense_weight=0.8,
                sparse_weight=0.2,
                normalization="min_max",
                candidates_multiplier=3
            )
            
            logger.info(f"Vietnamese Query Module initialized successfully with hybrid search and reranking")
            
        except Exception as e:
            logger.error(f"Error initializing Vietnamese Query Module: {e}")
            raise

    def authenticate(self) -> None:
        creds = None
        
        # Check if token file exists and load it directly
        if os.path.exists(self.token_path):
            try:
                # Load token data
                token_data = json.load(open(self.token_path))
                
                # Create credentials using the token data
                creds = Credentials.from_authorized_user_info(token_data)
                
                # If token is expired but has refresh token, refresh it
                if creds.expired and creds.refresh_token:
                    creds.refresh(Request())
                    # Save the refreshed token
                    with open(self.token_path, 'w') as token:
                        token.write(creds.to_json())
                    logger.info(f"Refreshed and saved authentication token to {self.token_path}")
            except Exception as e:
                logger.error(f"Error loading or refreshing token file: {e}")
                raise
        else:
            logger.error(f"Token file not found at {self.token_path}")
            raise FileNotFoundError(f"Token file not found: {self.token_path}")
                
        # Build Gmail service
        try:
            self.service = build('gmail', 'v1', credentials=creds)
            logger.info("Successfully authenticated with Gmail API")
            
            # Initialize managers after authentication
            self._initialize_managers()
        except Exception as e:
            logger.error(f"Error building Gmail service: {e}")
            raise
            
    async def fetch_unread_emails(self) -> List[Dict[str, Any]]:
        """
        Fetch unread emails from Gmail inbox and process them.
        
        Returns:
            List of unread email messages
            
        Raises:
            Exception: If fetching emails fails
        """
        if not self.service:
            try:
                self.authenticate()
            except Exception as e:
                logger.error(f"Authentication failed: {e}")
                return []
                
        try:
            # Get unread messages
            results = self.service.users().messages().list(
                userId=self.user_id, 
                q="is:unread").execute()
                
            messages = results.get('messages', [])
            
            if not messages:
                logger.debug("No unread messages found")
                return []
                
            # Fetch details for each message
            email_details = []
            for message in messages:
                msg = self.service.users().messages().get(
                    userId=self.user_id, 
                    id=message['id']).execute()
                    
                # Extract headers
                headers = {header['name']: header['value'] 
                          for header in msg['payload']['headers']}
                
                # Extract body
                body = self._get_email_body(msg)
                
                email_details.append({
                    'id': message['id'],
                    'threadId': msg['threadId'],
                    'from': headers.get('From', ''),
                    'to': headers.get('To', ''),
                    'subject': headers.get('Subject', ''),
                    'date': headers.get('Date', ''),
                    'body': body
                })
            
            if email_details:
                logger.info(f"Fetched {len(email_details)} unread emails, processing...")
                await self._group_and_process_emails(email_details)
            
            return email_details
            
        except HttpError as e:
            logger.error(f"Error fetching emails: {e}")
            return []
        except Exception as e:
            logger.error(f"Unexpected error: {e}")
            return []
            
    def _get_email_body(self, message: Dict) -> str:
        """
        Extract email body from Gmail message, including processing images with Gemini
        
        Args:
            message: Gmail message object
            
        Returns:
            Processed email body content
        """
        try:
            message_id = message.get('id')
            payload = message.get('payload', {})
            
            email_text = extract_text_content(payload)
            
            image_attachments = extract_image_attachments(self.service, self.user_id, payload, message_id)
            
            # Process attachments with Gemini if present
            if image_attachments:
                try:
                    logger.info(f"Processing {len(image_attachments)} images with Gemini")
                    return self.gemini_processor.process_email_with_attachments(
                        email_text=email_text, 
                        image_attachments=image_attachments,
                        pdf_attachments=[]
                    )
                except Exception as e:
                    logger.error(f"Gemini error: {e}")
            
            # Add image info if present
            if image_attachments:
                image_info = f"\n\n=== áº¢NH ÄÃNH KÃˆM ===\n"
                for i, img in enumerate(image_attachments, 1):
                    image_info += f"ðŸ“· áº¢nh {i}: {img.get('filename', f'image_{i}')}\n"
                return email_text + image_info
            
            return email_text
            
        except Exception as e:
            logger.error(f"Error extracting email body: {e}")
            return "[Lá»—i trÃ­ch xuáº¥t ná»™i dung email]"
    

    
    def mark_as_read(self, message_id: str) -> None:
        """
        Mark an email as read.
        
        Args:
            message_id: Gmail message ID
            
        Raises:
            Exception: If marking as read fails
        """
        try:
            self.service.users().messages().modify(
                userId=self.user_id,
                id=message_id,
                body={'removeLabelIds': ['UNREAD']}
            ).execute()
            logger.info(f"Marked message {message_id} as read")
        except Exception as e:
            logger.error(f"Error marking message as read: {e}")
            raise
            

    async def create_draft_email(self, to: str, subject: str, body: str, thread_id: str = None) -> str:
        """
        Create a draft email in Gmail.
        
        Args:
            to: Recipient email address
            subject: Email subject
            body: Email body
            thread_id: Thread ID for linking draft to specific thread
            
        Returns:
            Draft ID if successful, None if failed
            
        Raises:
            Exception: If creating draft fails
        """
        try:
            message = MIMEMultipart()
            message['to'] = to
            message['subject'] = f"Re: {subject}"
            
            msg = MIMEText(body)
            message.attach(msg)
            
            encoded_message = base64.urlsafe_b64encode(
                message.as_bytes()).decode()
            
            draft_body = {'message': {'raw': encoded_message}}
            
            if thread_id:
                draft_body['message']['threadId'] = thread_id
                logger.info(f"Linking draft to thread: {thread_id}")
            else:
                logger.warning("No thread_id provided - draft will not be linked to any thread")
                
            draft = self.service.users().drafts().create(
                userId=self.user_id,
                body=draft_body
            ).execute()
            
            draft_id = draft['id']
            
            logger.info(f"Draft created with ID: {draft_id} {'(linked to thread: ' + thread_id + ')' if thread_id else '(no thread link)'}")
            return draft_id
            
        except Exception as e:
            logger.error(f"Error creating draft: {e}")
            raise
            
    def process_email_with_vietnamese_query_module(self, email_body: str) -> tuple[str, str]:
        try:
            if self.query_module is None:
                self._init_query_module()
            
            logger.info("Processing email with Vietnamese Query Module")
            results, conversation = self.query_module.process_email(email_body)
            
            if not results:
                logger.warning("No results from Vietnamese Query Module")
                return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan Ä‘áº¿n cÃ¢u há»i cá»§a báº¡n.", "Email khÃ´ng cÃ³ thÃ´ng tin liÃªn quan"
            
            # Validate conversation context
            if not conversation:
                logger.error("No conversation context available from query module")
                return "Lá»—i: KhÃ´ng cÃ³ context cuá»™c há»™i thoáº¡i Ä‘á»ƒ xá»­ lÃ½ email.", "Lá»—i conversation context"
            
            logger.info(f"Successfully obtained conversation context and {len(results)} query results")
            context_summary = results[0].context_summary if results else "TÃ³m táº¯t email lá»—i"
            
            logger.info(f"Summarizing {len(results)} results from query module")
            summarized_results = []
            
            for i in range(0, len(results), 2):
                group = results[i:i+2]  # Get group of 2 (or 1 if odd number)
                logger.debug(f"Processing group {i//2 + 1}: {len(group)} queries")
                
                group_info = ""
                group_queries = []
                
                for j, result in enumerate(group):
                    query = result.original_query
                    group_queries.append(query)
                    
                    # Format information for this query
                    if result.results:
                        group_info += f"CÃ¢u há»i {j+1}: {query}\n"
                        for k, result_item in enumerate(result.results):
                            # Extract content and metadata
                            content = result_item.get("content", "") if isinstance(result_item, dict) else str(result_item)
                            metadata = result_item.get("metadata", {}) if isinstance(result_item, dict) else {}
                            file_created_at = metadata.get("file_created_at")
                            source = metadata.get("source")
                            
                            group_info += f"TÃ i liá»‡u {k+1}:"
                            if file_created_at:
                                group_info += f" (Cáº­p nháº­t: {file_created_at})"
                            if source and not source.startswith("gmail_thread"):
                                group_info += f" [Nguá»“n: {source}]"
                            group_info += f"\n{content}\n\n"
                    else:
                        group_info += f"CÃ¢u há»i {j+1}: {query}\nKhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan.\n\n"
                
                summarization_prompt = f"""
                HÃ£y tÃ³m táº¯t láº¡i cÃ¡c ná»™i dung liÃªn quan Ä‘áº¿n cÃ¡c cÃ¢u há»i vÃ  context sau má»™t cÃ¡ch chÃ­nh xÃ¡c, Ä‘áº§y Ä‘á»§ thÃ´ng tin, sÃºc tÃ­ch:
                Context: {email_body}
                
                CÃ¡c cÃ¢u há»i: {', '.join(group_queries)}
                
                ThÃ´ng tin liÃªn quan:
                {group_info}
                
                LÆ¯U Ã QUAN TRá»ŒNG:
                - Náº¿u cÃ³ nhiá»u tÃ i liá»‡u vá» cÃ¹ng má»™t chá»§ Ä‘á» vá»›i cÃ¡c ngÃ y cáº­p nháº­t khÃ¡c nhau, chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« tÃ i liá»‡u cÃ³ ngÃ y cáº­p nháº­t má»›i nháº¥t.
                - Khi sá»­ dá»¥ng thÃ´ng tin tá»« tÃ i liá»‡u cÃ³ ngÃ y cáº­p nháº­t, hÃ£y ghi rÃµ ngÃ y cáº­p nháº­t Ä‘Ã³ trong tÃ³m táº¯t (vÃ­ dá»¥: "Theo thÃ´ng tin cáº­p nháº­t ngÃ y 15/03/2024, thá»§ tá»¥c lÃ m báº±ng tá»‘t nghiá»‡p yÃªu cáº§u...").
                - Khi cÃ³ thÃ´ng tin nguá»“n tÃ i liá»‡u, hÃ£y ghi rÃµ nguá»“n trong tÃ³m táº¯t Ä‘á»ƒ cÃ³ thá»ƒ trÃ­ch dáº«n sau nÃ y.
                - Äá»‘i vá»›i thÃ´ng tin chá»‰ cÃ³ má»™t tÃ i liá»‡u hoáº·c khÃ´ng cÃ³ ngÃ y cáº­p nháº­t rÃµ rÃ ng, khÃ´ng cáº§n ghi ngÃ y cáº­p nháº­t.
                - Äáº£m báº£o tÃ³m táº¯t bao gá»“m thÃ´ng tin cáº­p nháº­t nháº¥t vá» tá»«ng váº¥n Ä‘á».
                """
                
                # Use conversation memory only to maintain context
                if conversation and self.deepseek_client:
                    try:
                        summary_response = self.deepseek_client.send_message(
                            conversation=conversation,
                            message=summarization_prompt,
                            temperature=0.3,
                            max_tokens=8000,
                            error_default=f"KhÃ´ng tÃ¬m Ä‘Æ°á»£c thÃ´ng tin cho cÃ¡c cÃ¢u há»i: {', '.join(group_queries)}"
                        )
                    except Exception as e:
                        logger.error(f"Error in conversation-based summarization for queries {group_queries}: {e}")
                        summary_response = f"Lá»—i xá»­ lÃ½ thÃ´ng tin cho cÃ¡c cÃ¢u há»i: {', '.join(group_queries)}"
                else:
                    logger.error("No conversation context available for summarization")
                    summary_response = f"KhÃ´ng cÃ³ context xá»­ lÃ½ cho cÃ¡c cÃ¢u há»i: {', '.join(group_queries)}"
                
                summarized_results.append({
                    "queries": group_queries,
                    "summary": summary_response
                })
            
            email_prompt = f"""Báº¡n lÃ  má»™t trá»£ lÃ½ AI há»— trá»£ phÃ²ng cÃ´ng tÃ¡c sinh viÃªn trong viá»‡c tráº£ lá»i email.
DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung email tá»« sinh viÃªn:

{email_body}

Dá»±a trÃªn ná»™i dung email vÃ  thÃ´ng tin tÃ¬m tháº¥y, hÃ£y soáº¡n má»™t email pháº£n há»“i:
"""
            for i, summary in enumerate(summarized_results):
                email_prompt += f"NhÃ³m thÃ´ng tin {i+1}: {summary['summary']}\n"
            
            email_prompt += """
Dá»±a trÃªn cÃ¡c thÃ´ng tin trÃªn, hÃ£y soáº¡n má»™t email pháº£n há»“i:
- TrÃ¬nh bÃ y báº±ng tiáº¿ng Viá»‡t chuáº©n, Ä‘Ãºng chÃ­nh táº£, dá»… hiá»ƒu.
- Äáº¶C BIá»†T QUAN TRá»ŒNG: Viáº¿t email dÆ°á»›i dáº¡ng vÄƒn báº£n thuáº§n (plain text), KHÃ”NG sá»­ dá»¥ng markdown format hay báº¥t ká»³ Ä‘á»‹nh dáº¡ng nÃ o khÃ¡c.
- Tráº£ lá»i láº§n lÆ°á»£t tá»«ng cÃ¢u há»i, dá»±a vÃ o thÃ´ng tin Ä‘Ã£ tÃ³m táº¯t.
- Äáº¶C BIá»†T QUAN TRá»ŒNG: Náº¿u biáº¿t thÃ´ng tin Ä‘Æ°á»£c cáº­p nháº­t vÃ o ngÃ y nÃ o (cÃ³ ngÃ y cáº­p nháº­t cá»¥ thá»ƒ), hÃ£y ghi rÃµ ngÃ y cáº­p nháº­t Ä‘Ã³ trong cÃ¢u tráº£ lá»i Ä‘á»ƒ ngÆ°á»i dÃ¹ng biáº¿t Ä‘Ã¢y lÃ  thÃ´ng tin má»›i nháº¥t. VÃ­ dá»¥: "Theo thÃ´ng tin cáº­p nháº­t ngÃ y 15/03/2024, quy trÃ¬nh Ä‘Äƒng kÃ½ há»c pháº§n Ä‘Ã£ thay Ä‘á»•i..."
- Äáº¶C BIá»†T QUAN TRá»ŒNG: Khi cÃ³ thÃ´ng tin nguá»“n tÃ i liá»‡u, hÃ£y trÃ­ch dáº«n nguá»“n thÃ´ng tin á»Ÿ cuá»‘i email vÃ  cÃ¡ch Ä‘Ã¡nh dáº¥u footnotes á»Ÿ pháº§n thÃ´ng tin.
- Äá»‘i vá»›i cÃ¡c thÃ´ng tin khÃ´ng cÃ³ ngÃ y cáº­p nháº­t cá»¥ thá»ƒ, tráº£ lá»i bÃ¬nh thÆ°á»ng khÃ´ng cáº§n ghi ngÃ y.
- Náº¿u khÃ´ng cÃ³ Ä‘á»§ thÃ´ng tin, hÃ£y Ä‘á» xuáº¥t ngÆ°á»i gá»­i liÃªn há»‡ bá»™ pháº­n cÃ³ tháº©m quyá»n hoáº·c cung cáº¥p thÃªm chi tiáº¿t.
- Äáº£m báº£o Ä‘á»‹nh dáº¡ng email hÃ nh chÃ­nh: lá»i chÃ o, ná»™i dung chÃ­nh, lá»i káº¿t, kÃ½ tÃªn.

Viáº¿t email pháº£n há»“i ngay dÆ°á»›i Ä‘Ã¢y (chá»‰ tráº£ vá» ná»™i dung email thuáº§n(plain text)):
"""
            
            # Use conversation memory only for final email generation to maintain context
            if conversation and self.deepseek_client:
                try:
                    email_response = self.deepseek_client.send_message(
                        conversation=conversation,
                        message=email_prompt,
                        temperature=0.5,
                        max_tokens=4000,
                        error_default="CÃ³ lá»—i xáº£y ra khi táº¡o email pháº£n há»“i."
                    )
                except Exception as e:
                    logger.error(f"Error in conversation-based email generation: {e}")
                    email_response = "Xin lá»—i, cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh táº¡o email pháº£n há»“i. Vui lÃ²ng thá»­ láº¡i sau."
            else:
                logger.error("No conversation context available for email generation")
                email_response = "KhÃ´ng cÃ³ context cuá»™c há»™i thoáº¡i Ä‘á»ƒ táº¡o email pháº£n há»“i."
            
            return email_response, context_summary
            
        except Exception as e:
            logger.warning(f"Error processing email with Vietnamese Query Module: {e}")
            return "Xin lá»—i, cÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ email. Vui lÃ²ng liÃªn há»‡ trá»±c tiáº¿p Ä‘á»ƒ Ä‘Æ°á»£c há»— trá»£.", "Lá»—i xá»­ lÃ½ email"
    
    def process_text_with_vietnamese_query_module(self, text_content: str) -> str:
        """
        Process general text content with Vietnamese Query Module and generate comprehensive response
        
        Args:
            text_content: Input text content to process
            
        Returns:
            str: Comprehensive response with information and sources
        """
        try:
            if self.query_module is None:
                self._init_query_module()
            
            logger.info("Processing text with Vietnamese Query Module")
            results, conversation = self.query_module.process_text(text_content)
            
            if not results:
                logger.warning("No results from Vietnamese Query Module for text")
                return "KhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan Ä‘áº¿n ná»™i dung cá»§a báº¡n."
            
            # Validate conversation context
            if not conversation:
                logger.error("No conversation context available from query module")
                return "Lá»—i: KhÃ´ng cÃ³ context cuá»™c há»™i thoáº¡i Ä‘á»ƒ xá»­ lÃ½ vÄƒn báº£n."
            
            logger.info(f"Successfully obtained conversation context and {len(results)} query results")
            
            logger.info(f"Summarizing {len(results)} results from query module")
            summarized_results = []
            
            for i in range(0, len(results), 2):
                group = results[i:i+2]  # Get group of 2 (or 1 if odd number)
                logger.debug(f"Processing group {i//2 + 1}: {len(group)} queries")
                
                group_info = ""
                group_queries = []
                
                for j, result in enumerate(group):
                    query = result.original_query
                    group_queries.append(query)
                    
                    # Format information for this query
                    if result.results:
                        group_info += f"CÃ¢u há»i {j+1}: {query}\n"
                        for k, result_item in enumerate(result.results):
                            # Extract content and metadata
                            content = result_item.get("content", "") if isinstance(result_item, dict) else str(result_item)
                            metadata = result_item.get("metadata", {}) if isinstance(result_item, dict) else {}
                            file_created_at = metadata.get("file_created_at")
                            source = metadata.get("source")
                            
                            group_info += f"TÃ i liá»‡u {k+1}:"
                            if file_created_at:
                                group_info += f" (Cáº­p nháº­t: {file_created_at})"
                            if source and not source.startswith("gmail_thread"):
                                group_info += f" [Nguá»“n: {source}]"
                            group_info += f"\n{content}\n\n"
                    else:
                        group_info += f"CÃ¢u há»i {j+1}: {query}\nKhÃ´ng tÃ¬m tháº¥y thÃ´ng tin liÃªn quan.\n\n"
                
                summarization_prompt = f"""
                HÃ£y tÃ³m táº¯t láº¡i cÃ¡c ná»™i dung liÃªn quan Ä‘áº¿n cÃ¡c cÃ¢u há»i vÃ  context sau má»™t cÃ¡ch chÃ­nh xÃ¡c, Ä‘áº§y Ä‘á»§ thÃ´ng tin, sÃºc tÃ­ch:
                Context: {text_content}
                
                CÃ¡c cÃ¢u há»i: {', '.join(group_queries)}
                
                ThÃ´ng tin liÃªn quan:
                {group_info}
                
                LÆ¯U Ã QUAN TRá»ŒNG:
                - Náº¿u cÃ³ nhiá»u tÃ i liá»‡u vá» cÃ¹ng má»™t chá»§ Ä‘á» vá»›i cÃ¡c ngÃ y cáº­p nháº­t khÃ¡c nhau, chá»‰ sá»­ dá»¥ng thÃ´ng tin tá»« tÃ i liá»‡u cÃ³ ngÃ y cáº­p nháº­t má»›i nháº¥t, vÃ  ghi rÃµ ngÃ y cáº­p nháº­t Ä‘Ã³ trong tÃ³m táº¯t (vÃ­ dá»¥: "Theo thÃ´ng tin cáº­p nháº­t ngÃ y 15/03/2024, thá»§ tá»¥c lÃ m báº±ng tá»‘t nghiá»‡p yÃªu cáº§u...").
                - CÃ¡c ná»™i dung khÃ´ng trÃ¹ng láº·p thÃ¬ khÃ´ng cáº§n ghi rÃµ ngÃ y cáº­p nháº­t.
                - Khi cÃ³ thÃ´ng tin nguá»“n tÃ i liá»‡u, giá»¯ nguyÃªn thÃ´ng tin nguá»“n tÃ i liá»‡u Ä‘á»ƒ trÃ­ch dáº«n báº±ng footnotes á»Ÿ cuá»‘i ná»™i dung.
                """
                
                # Use conversation memory to maintain context
                if conversation and self.deepseek_client:
                    try:
                        summary_response = self.deepseek_client.send_message(
                            conversation=conversation,
                            message=summarization_prompt,
                            temperature=0.3,
                            max_tokens=8000,
                            error_default=f"KhÃ´ng tÃ¬m Ä‘Æ°á»£c thÃ´ng tin cho cÃ¡c cÃ¢u há»i: {', '.join(group_queries)}"
                        )
                    except Exception as e:
                        logger.error(f"Error in conversation-based summarization for queries {group_queries}: {e}")
                        summary_response = f"Lá»—i xá»­ lÃ½ thÃ´ng tin cho cÃ¡c cÃ¢u há»i: {', '.join(group_queries)}"
                else:
                    logger.error("No conversation context available for summarization")
                    summary_response = f"KhÃ´ng cÃ³ context xá»­ lÃ½ cho cÃ¡c cÃ¢u há»i: {', '.join(group_queries)}"
                
                summarized_results.append({
                    "queries": group_queries,
                    "summary": summary_response
                })
            
            response_prompt = f"""Báº¡n lÃ  má»™t trá»£ lÃ½ AI há»— trá»£ 
DÆ°á»›i Ä‘Ã¢y lÃ  ná»™i dung cáº§n xá»­ lÃ½:

{text_content}

Dá»±a trÃªn ná»™i dung vÃ  thÃ´ng tin tÃ¬m tháº¥y, hÃ£y táº¡o má»™t pháº£n há»“i Ä‘áº§y Ä‘á»§:
"""
            for i, summary in enumerate(summarized_results):
                response_prompt += f"NhÃ³m thÃ´ng tin {i+1}: {summary['summary']}\n"
            
            response_prompt += """
Dá»±a trÃªn cÃ¡c thÃ´ng tin trÃªn, hÃ£y táº¡o má»™t pháº£n há»“i Ä‘áº§y Ä‘á»§:
- TrÃ¬nh bÃ y báº±ng tiáº¿ng Viá»‡t chuáº©n, Ä‘Ãºng chÃ­nh táº£, dá»… hiá»ƒu.
- Äáº¶C BIá»†T QUAN TRá»ŒNG: Viáº¿t pháº£n há»“i dÆ°á»›i dáº¡ng vÄƒn báº£n thuáº§n (plain text), KHÃ”NG sá»­ dá»¥ng markdown format hay báº¥t ká»³ Ä‘á»‹nh dáº¡ng nÃ o khÃ¡c.
- Tráº£ lá»i láº§n lÆ°á»£t tá»«ng cÃ¢u há»i hoáº·c váº¥n Ä‘á» Ä‘Æ°á»£c Ä‘áº·t ra, dá»±a vÃ o thÃ´ng tin Ä‘Ã£ tÃ³m táº¯t.
- Äáº¶C BIá»†T QUAN TRá»ŒNG: Náº¿u biáº¿t thÃ´ng tin Ä‘Æ°á»£c cáº­p nháº­t vÃ o ngÃ y nÃ o (cÃ³ ngÃ y cáº­p nháº­t cá»¥ thá»ƒ), hÃ£y ghi rÃµ ngÃ y cáº­p nháº­t Ä‘Ã³ trong cÃ¢u tráº£ lá»i Ä‘á»ƒ ngÆ°á»i dÃ¹ng biáº¿t Ä‘Ã¢y lÃ  thÃ´ng tin má»›i nháº¥t. VÃ­ dá»¥: "Theo thÃ´ng tin cáº­p nháº­t ngÃ y 15/03/2024, quy trÃ¬nh Ä‘Äƒng kÃ½ há»c pháº§n Ä‘Ã£ thay Ä‘á»•i..."
- Äáº¶C BIá»†T QUAN TRá»ŒNG: Khi cÃ³ thÃ´ng tin nguá»“n tÃ i liá»‡u, hÃ£y trÃ­ch dáº«n nguá»“n thÃ´ng tin á»Ÿ cuá»‘i pháº£n há»“i vÃ  Ä‘Ã¡nh dáº¥u footnotes á»Ÿ pháº§n thÃ´ng tin.
- Äá»‘i vá»›i cÃ¡c thÃ´ng tin khÃ´ng cÃ³ ngÃ y cáº­p nháº­t cá»¥ thá»ƒ, tráº£ lá»i bÃ¬nh thÆ°á»ng khÃ´ng cáº§n ghi ngÃ y.
- Äáº£m báº£o pháº£n há»“i cÃ³ cáº¥u trÃºc rÃµ rÃ ng: giá»›i thiá»‡u ngáº¯n, ná»™i dung chÃ­nh, káº¿t luáº­n.

Viáº¿t pháº£n há»“i ngay dÆ°á»›i Ä‘Ã¢y (chá»‰ tráº£ vá» ná»™i dung thuáº§n (plain text)):
"""
            
            # Use conversation memory for final response generation
            if conversation and self.deepseek_client:
                try:
                    final_response = self.deepseek_client.send_message(
                        conversation=conversation,
                        message=response_prompt,
                        temperature=0.5,
                        max_tokens=4000,
                        error_default="CÃ³ lá»—i xáº£y ra khi táº¡o pháº£n há»“i."
                    )
                except Exception as e:
                    logger.error(f"Error in conversation-based response generation: {e}")
                    final_response = "Xin lá»—i, cÃ³ lá»—i xáº£y ra trong quÃ¡ trÃ¬nh táº¡o pháº£n há»“i. Vui lÃ²ng thá»­ láº¡i sau."
            else:
                logger.error("No conversation context available for response generation")
                final_response = "KhÃ´ng cÃ³ context cuá»™c há»™i thoáº¡i Ä‘á»ƒ táº¡o pháº£n há»“i."
            
            return final_response
            
        except Exception as e:
            logger.warning(f"Error processing text with Vietnamese Query Module: {e}")
            return "Xin lá»—i, cÃ³ lá»—i xáº£y ra khi xá»­ lÃ½ vÄƒn báº£n. Vui lÃ²ng thá»­ láº¡i sau."

    async def _group_and_process_emails(self, unread_emails: List[Dict[str, Any]]) -> None:
        if not unread_emails:
            return
            
        thread_emails = {}
        for email in unread_emails:
            thread_id = email['threadId']
            if thread_id not in thread_emails:
                thread_emails[thread_id] = []
            thread_emails[thread_id].append(email)
        
        for thread_id, emails in thread_emails.items():
            logger.info(f"Processing thread {thread_id} with {len(emails)} email(s)")
            await self.process_thread_with_context(thread_id, emails)

    async def process_thread_with_context(self, thread_id: str, unread_emails: List[Dict[str, Any]]) -> None:
        existing_draft_id = self.draft_monitor.check_existing_draft(thread_id)
        if existing_draft_id:
            logger.info(f"Thread {thread_id} has existing draft {existing_draft_id}, deleting")
            self.draft_monitor.delete_draft(existing_draft_id)
        
        thread_info = self.metadata_db.get_gmail_thread_info(thread_id)
        
        context_parts = []
        
        if thread_info and thread_info.get('context_summary'):
            context_parts.append(f"=== CONTEXT Tá»ª CUá»˜C Há»˜I THOáº I TRÆ¯á»šC ===\n{thread_info['context_summary']}\n")
        
        recent_responses = await self._fetch_responses_since_last_processed(
            thread_id, thread_info.get('last_processed_message_id') if thread_info else None
        )
        
        if recent_responses:
            context_parts.append("=== Lá»ŠCH Sá»¬ TÆ¯Æ NG TÃC Gáº¦N ÄÃ‚Y ===\n")
            for i, response in enumerate(recent_responses, 1):
                context_parts.append(f"Tá»«: {response['from']}\n")
                context_parts.append(f"TiÃªu Ä‘á»: {response['subject']}\n")
                context_parts.append(f"Ná»™i dung: {response['body']}\n\n")
            context_parts.append("\n")
        
        context_parts.append("=== EMAIL CHÆ¯A Äá»ŒC Cáº¦N Xá»¬ LÃ ===\n")
        for i, email in enumerate(unread_emails, 1):
            context_parts.append(f"Tá»«: {email['from']}\n")
            context_parts.append(f"TiÃªu Ä‘á»: {email['subject']}\n")
            context_parts.append(f"Ná»™i dung: {email['body']}\n\n")
        
        full_context = "".join(context_parts)
        
        if not full_context.strip():
            logger.warning(f"Empty context for thread {thread_id}")
            return
        
        logger.info(f"Processing thread {thread_id} with comprehensive context")
        response_text, context_summary = self.process_email_with_vietnamese_query_module(full_context)
        
        newest_email = unread_emails[-1]
            
        to_address = newest_email['from']
        newest_subject = newest_email['subject']
        
        try:
            draft_id = await self.create_draft_email(
                to=to_address,
                subject=newest_subject,
                body=response_text,
                thread_id=thread_id
            )
            
            if draft_id:
                last_message_id = newest_email['id']
                self.metadata_db.upsert_gmail_thread(
                    thread_id=thread_id,
                    context_summary=context_summary,
                    current_draft_id=draft_id,
                    last_processed_message_id=last_message_id
                )
                
                marked_count = 0
                for email in unread_emails:
                    try:
                        self.mark_as_read(email['id'])
                        marked_count += 1
                    except Exception as mark_error:
                        logger.error(f"Failed to mark email {email['id']} as read: {mark_error}")
                
                logger.info(f"Successfully processed thread {thread_id}, draft ID: {draft_id}, marked {marked_count}/{len(unread_emails)} emails as read")
            else:
                logger.error(f"Failed to create draft for thread {thread_id}")
                
        except Exception as e:
            logger.error(f"Draft creation failed for thread {thread_id}: {e}")
            raise

    async def _fetch_responses_since_last_processed(self, thread_id: str, last_processed_message_id: str = None) -> List[Dict[str, Any]]:
        try:
            thread_messages = self.service.users().threads().get(
                userId=self.user_id, 
                id=thread_id,
                format='full'
            ).execute()
            
            messages = thread_messages.get('messages', [])
            admin_responses = []
            
            # If no last processed message ID, don't include any history
            if last_processed_message_id is None:
                logger.debug(f"No last processed message ID for thread {thread_id}, skipping history")
                return []
            
            found_last_processed = False
            
            for message in messages:
                if message['id'] == last_processed_message_id:
                    found_last_processed = True
                    continue  # Skip the last processed message itself
                
                if not found_last_processed:
                    continue  # Haven't found the starting point yet
                
                headers = {h['name']: h['value'] for h in message['payload']['headers']}
                message_from = headers.get('From', '')
                body = self._get_email_body(message)
                
                if body.strip():
                    admin_responses.append({
                        'id': message['id'],
                        'from': message_from,
                        'date': headers.get('Date', ''),
                        'body': body
                    })
            
            # If we never found the last processed message, it might have been deleted
            if not found_last_processed and last_processed_message_id:
                logger.warning(f"Last processed message {last_processed_message_id} not found in thread {thread_id}")
                # Return limited recent messages to avoid overwhelming context
                for message in messages[-5:]:  # Only last 5 messages
                    headers = {h['name']: h['value'] for h in message['payload']['headers']}
                    message_from = headers.get('From', '')
                    body = self._get_email_body(message)
                    
                    if body.strip():
                        admin_responses.append({
                            'id': message['id'],
                            'from': message_from,
                            'date': headers.get('Date', ''),
                            'body': body
                        })
            
            logger.info(f"Found {len(admin_responses)} messages for thread {thread_id}")
            return admin_responses
            
        except Exception as e:
            logger.error(f"Error fetching responses for thread {thread_id}: {e}")
            return []

    async def run(self) -> None:
        
        if not self.service:
            self.authenticate()
            
        if not self.draft_monitor or not self.api_monitor:
            self._initialize_managers()
        
        if not self.background_worker:
            self._init_background_worker()
        
        logger.info("Starting Gmail monitoring with API polling")
        
        await self.api_monitor.start_monitoring()
        logger.info("Gmail API polling monitoring started")
                
async def start_gmail_monitoring(gmail_handler=None):
    if gmail_handler:
        logger.info("Using injected Gmail handler for monitoring")
        handler = gmail_handler
    else:
        logger.info("Creating new Gmail handler for monitoring")
        handler = GmailHandler()
    
    await handler.run()
